{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Autoencoder Simple: Formulación Matemática**\n",
    "---\n",
    "\n",
    "## 1. Definición del Autoencoder\n",
    "Un **autoencoder** es una función compuesta $ h: \\mathcal{X} \\to \\mathcal{X} $ definida por la composición de dos funciones diferenciables:\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}) = g_{\\phi}\\bigl(f_{\\theta}(\\mathbf{x})\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $f_{\\theta}: \\mathcal{X} \\to \\mathbb{R}^m$ es la **función de codificación (encoder)**.\n",
    "- $g_{\\phi}: \\mathbb{R}^m \\to \\mathcal{X}$ es la **función de decodificación (decoder)**.\n",
    "\n",
    "El objetivo del autoencoder es encontrar los parámetros $\\theta$ y $\\phi$ tales que $h(\\mathbf{x}) \\approx \\mathbf{x}$, minimizando una función de pérdida adecuada.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Codificador (Encoder)\n",
    "El encoder transforma la entrada $\\mathbf{x} \\in \\mathbb{R}^n$ en una representación latente $\\mathbf{z} \\in \\mathbb{R}^m$, con $m < n$ en el caso de reducción de dimensionalidad:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = f_{\\theta}(\\mathbf{x}) = \\sigma\\bigl(W_e \\,\\mathbf{x} + \\mathbf{b}_e\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $W_e \\in \\mathbb{R}^{m \\times n}$ es la **matriz de pesos del encoder**.\n",
    "- $\\mathbf{b}_e \\in \\mathbb{R}^{m}$ es el **vector de sesgo**.\n",
    "- $\\sigma: \\mathbb{R} \\to \\mathbb{R}$ es una función de activación (e.g., **ReLU**, **Sigmoid**, **Tanh**).\n",
    "- $\\mathbf{z} \\in \\mathbb{R}^{m}$ es la representación latente.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Decodificador (Decoder)\n",
    "El decoder reconstruye la entrada original a partir de $\\mathbf{z}$:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}} = g_{\\phi}(\\mathbf{z}) = \\sigma'\\bigl(W_d \\,\\mathbf{z} + \\mathbf{b}_d\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $W_d \\in \\mathbb{R}^{n \\times m}$ es la **matriz de pesos del decoder**.\n",
    "- $\\mathbf{b}_n \\in \\mathbb{R}^{n}$ es el **vector de sesgo**.\n",
    "- $\\sigma': \\mathbb{R} \\to \\mathbb{R}$ es una función de activación (puede diferir de $\\sigma$).\n",
    "- $\\hat{\\mathbf{x}} \\in \\mathbb{R}^n$ es la **reconstrucción de la entrada**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Función de Pérdida\n",
    "Para un conjunto de datos \n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{\\mathbf{x}_i\\}_{i=1}^{N},\n",
    "$$\n",
    "\n",
    "el entrenamiento del autoencoder minimiza la diferencia entre la entrada $\\mathbf{x}_i$ y la reconstrucción $\\hat{\\mathbf{x}}_i$. Usamos el **Error Cuadrático Medio (MSE)** promediado:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{MSE} = \\frac{1}{N} \\sum_{i=1}^{N}\n",
    "\\left(\n",
    "    \\frac{1}{d} \\sum_{j=1}^{d} \n",
    "    \\bigl(x_{i,j} - \\hat{x}_{i,j}\\bigr)^2\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $N$ es el número total de muestras.\n",
    "- $d$ es la dimensión de cada muestra $\\mathbf{x}_i$.\n",
    "- $x_{i,j}$ y $\\hat{x}_{i,j}$ representan la $j$-ésima componente de la muestra $\\mathbf{x}_i$ y de su reconstrucción, respectivamente.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Optimización\n",
    "El objetivo es encontrar los parámetros $\\theta$ y $\\phi$ que minimicen la función de pérdida:\n",
    "\n",
    "$$\n",
    "\\theta^*, \\phi^* = \\arg \\min_{\\theta, \\phi} \\,\\mathcal{L}_{MSE}.\n",
    "$$\n",
    "\n",
    "La optimización se resuelve mediante **descenso de gradiente**, por ejemplo usando una tasa de aprendizaje $\\eta$:\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta - \\eta\\,\\nabla_{\\theta} \\,\\mathcal{L}_{MSE},\n",
    "\\quad\n",
    "\\phi \\leftarrow \\phi - \\eta\\,\\nabla_{\\phi} \\,\\mathcal{L}_{MSE}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Resumen\n",
    "\n",
    "1. **Encoder:**  \n",
    "   $$\n",
    "   \\mathbf{z} = \\sigma\\bigl(W_e \\,\\mathbf{x} + \\mathbf{b}_e\\bigr)\n",
    "   $$\n",
    "\n",
    "2. **Decoder:**  \n",
    "   $$\n",
    "   \\hat{\\mathbf{x}} = \\sigma'\\bigl(W_d \\,\\mathbf{z} + \\mathbf{b}_d\\bigr)\n",
    "   $$\n",
    "\n",
    "3. **Pérdida (MSE Promediado):**  \n",
    "   $$\n",
    "   \\mathcal{L}_{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} \\left(\\frac{1}{n} \\sum_{j=1}^{n} \\bigl(x_{i,j} - \\hat{x}_{i,j}\\bigr)^2\\right)\n",
    "   $$\n",
    "\n",
    "4. **Optimización:**  \n",
    "   $$\n",
    "   \\theta^*, \\phi^* = \\arg \\min_{\\theta, \\phi} \\,\\mathcal{L}_{MSE}\n",
    "   $$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Sparse Autoencoder**\n",
    "\n",
    "Los sparse autoencoder respetan la estrucuta generla de un autoencoder simple pero para lograr que sea **disperso**, se añade un término de penalización que fomenta activaciones promedio bajas en la capa latente:\n",
    "\n",
    "1. **Activación promedio de la neurona $j$:**  \n",
    "   Sea $\\mathbf{z}_i = f_{\\theta}(\\mathbf{x}_i)$ la salida del encoder para la muestra $i$. La **activación promedio** de la neurona $j$ es:\n",
    "\n",
    "   $$\n",
    "   \\hat{\\rho}_j = \\frac{1}{N}\\sum_{i=1}^N z_{i,j}.\n",
    "   $$\n",
    "\n",
    "2. **Penalización (Divergencia KL):**  \n",
    "   Se define $\\rho$ como la activación deseada (por ejemplo, $\\rho=0.05$). La desviación de $\\hat{\\rho}_j$ respecto a $\\rho$ se mide con la **Divergencia KL**:\n",
    "\n",
    "   $$\n",
    "   \\mathrm{KL}\\bigl(\\rho \\,\\|\\, \\hat{\\rho}_j\\bigr)\n",
    "   =\n",
    "   \\rho \\,\\log \\frac{\\rho}{\\hat{\\rho}_j}\n",
    "   \\;+\\;\n",
    "   (1-\\rho)\\,\\log \\frac{1-\\rho}{\\,1-\\hat{\\rho}_j}.\n",
    "   $$\n",
    "\n",
    "3. **Función de costo total (con dispersión):**  \n",
    "   El término de dispersión se agrega al MSE multiplicado por un factor $\\beta$:\n",
    "\n",
    "   $$\n",
    "   \\mathcal{L}_{Sparse}\n",
    "   =\n",
    "   \\mathcal{L}_{MSE}\n",
    "   \\;+\\;\n",
    "   \\beta \\sum_{j=1}^{m} \n",
    "   \\mathrm{KL}\\bigl(\\rho \\,\\|\\, \\hat{\\rho}_j\\bigr).\n",
    "   $$\n",
    "\n",
    "Este término adicional obliga a que la **activación promedio** de cada neurona $\\hat{\\rho}_j$ se acerque a $\\rho$, convirtiendo así un autoencoder normal en un **autoencoder *sparse***.\n",
    "\n",
    "## 1. Definición General de la Divergencia KL\n",
    "\n",
    "La divergencia KL entre dos distribuciones de probabilidad $P(x)$ y $Q(x)$ se define como:\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\,\\|\\, Q) \\;=\\; \\sum_{x} P(x)\\,\\log\\!\\Bigl(\\tfrac{P(x)}{Q(x)}\\Bigr).\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $P(x)$ es la distribución de referencia.\n",
    "- $Q(x)$ es la distribución que usamos para aproximar a $P(x)$.\n",
    "- La divergencia KL mide cuánta información se pierde cuando usamos $Q(x)$ en lugar de $P(x)$.\n",
    "---\n",
    "\n",
    "## 2. Aplicando la Divergencia KL a la Bernoulli\n",
    "\n",
    "Cuando $P$ y $Q$ son distribuciones de Bernoulli con parámetros $\\rho$ y $\\hat{\\rho}_j$, respectivamente, la variable aleatoria $X$ solo puede tomar los valores $0$ o $1$. Entonces:\n",
    "\n",
    "- Para $X = 1$:\n",
    "  \n",
    "  $$\n",
    "  P(1) = \\rho, \\quad Q(1) = \\hat{\\rho}_j.\n",
    "  $$\n",
    "  \n",
    "- Para $X = 0$:\n",
    "  \n",
    "  $$\n",
    "  P(0) = 1 - \\rho, \\quad Q(0) = 1 - \\hat{\\rho}_j.\n",
    "  $$\n",
    "\n",
    "Aplicamos la definición de la divergencia KL:\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\,\\|\\, Q) \n",
    "= \\sum_{x \\in \\{0,1\\}} P(x) \\log \\frac{P(x)}{Q(x)}.\n",
    "$$\n",
    "\n",
    "Sustituyendo los valores para la distribución Bernoulli:\n",
    "\n",
    "$$\n",
    "D_{KL}(\\text{Bern}(\\rho) \\,\\|\\, \\text{Bern}(\\hat{\\rho}_j))\n",
    "=\n",
    "\\rho \\,\\log\\!\\Bigl(\\tfrac{\\rho}{\\hat{\\rho}_j}\\Bigr)\n",
    "\\;+\\;\n",
    "(1-\\rho)\\,\\log\\!\\Bigl(\\tfrac{1-\\rho}{1-\\hat{\\rho}_j}\\Bigr).\n",
    "$$\n",
    "\n",
    "Esto nos da la divergencia KL específica para dos distribuciones Bernoulli.\n",
    "Así tenemos que la expresión anterior describe cuánta información se pierde cuando usamos una distribución Bernoulli con parámetro $\\hat{\\rho}_j$ para aproximar otra con parámetro $\\rho$. Es especialmente útil en problemas de modelado probabilístico y aprendizaje automático.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
