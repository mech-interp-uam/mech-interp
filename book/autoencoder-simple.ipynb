{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Autoencoders: Formulación Matemática**\n",
    "\n",
    "El estudio de los autoencoders, en general, es importante para poder interpretar lo que aprenden los modelos Transformer. Esta es una de las herramientas más \n",
    "utilizadas actualmente para la interpretación de dichos modelos. En esta sección se analizará la estructura matemática de los autoencoders simples y, posteriormente,\n",
    " de los autoencoders sparsos, los cuales incorporan pequeñas penalizaciones en la función de pérdida. Estas penalizaciones les otorgan propiedades particulares que \n",
    " pueden ser útiles para nuestros fines.\n",
    "\n",
    "\n",
    "## **Autoencoder Simple**\n",
    "\n",
    "\n",
    "### **Definición del Autoencoder**\n",
    "Un **autoencoder** es una función compuesta $ h: \\mathcal{X} \\to \\mathcal{X} $ definida por la composición de dos funciones diferenciables:\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}) = g_{\\phi}\\bigl(f_{\\theta}(\\mathbf{x})\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $f_{\\theta}: \\mathcal{X} \\to \\mathbb{R}^m$ es la **función de codificación (encoder)**.\n",
    "- $g_{\\phi}: \\mathbb{R}^m \\to \\mathcal{X}$ es la **función de decodificación (decoder)**.\n",
    "\n",
    "El objetivo del autoencoder es encontrar los parámetros $\\theta$ y $\\phi$ tales que $h(\\mathbf{x}) \\approx \\mathbf{x}$, minimizando una función de pérdida adecuada.\n",
    "\n",
    "\n",
    "### **Codificador (Encoder)**\n",
    "El encoder transforma la entrada $\\mathbf{x} \\in \\mathbb{R}^n$ en una representación latente $\\mathbf{z} \\in \\mathbb{R}^m$, con $m < n$ en el caso de reducción de dimensionalidad:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = f_{\\theta}(\\mathbf{x}) = \\sigma\\bigl(W_e \\,\\mathbf{x} + \\mathbf{b}_e\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $W_e \\in \\mathbb{R}^{m \\times n}$ es la **matriz de pesos del encoder**.\n",
    "- $\\mathbf{b}_e \\in \\mathbb{R}^{m}$ es el **vector de sesgo**.\n",
    "- $\\sigma: \\mathbb{R} \\to \\mathbb{R}$ es una función de activación (**ReLU**, **Sigmoid**, **Tanh**).\n",
    "- $\\mathbf{z} \\in \\mathbb{R}^{m}$ es la representación latente.\n",
    "\n",
    "\n",
    "### **Decodificador (Decoder)**\n",
    "El decoder reconstruye la entrada original a partir de $\\mathbf{z}$:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}} = g_{\\phi}(\\mathbf{z}) = \\sigma'\\bigl(W_d \\,\\mathbf{z} + \\mathbf{b}_d\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $W_d \\in \\mathbb{R}^{n \\times m}$ es la **matriz de pesos del decoder**.\n",
    "- $\\mathbf{b}_d \\in \\mathbb{R}^{n}$ es el **vector de sesgo**.\n",
    "- $\\sigma': \\mathbb{R} \\to \\mathbb{R}$ es una función de activación (puede diferir de $\\sigma$).\n",
    "- $\\hat{\\mathbf{x}} \\in \\mathbb{R}^n$ es la **reconstrucción de la entrada**.\n",
    "\n",
    "\n",
    "### **Función de Pérdida**\n",
    "\n",
    "Es importante considerar que la función de pérdida puede variar. En principio, el error cuadrático medio (Mean Squared Error, MSE) es una de las más utilizadas en autoencoders simples; sin embargo, dependiendo de la tarea a realizar, en algunos casos conviene más utilizar una u otra.\n",
    "\n",
    "Para un conjunto de datos \n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{\\mathbf{x}_i\\}_{i=1}^{N},\n",
    "$$\n",
    "\n",
    "el entrenamiento del autoencoder minimiza la diferencia entre la entrada $\\mathbf{x}_i$ y la reconstrucción $\\hat{\\mathbf{x}}_i$. Usamos el **Error Cuadrático Medio (MSE)** promediado:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{MSE} = \\frac{1}{N} \\sum_{i=1}^{N}\n",
    "\\left(\n",
    "    \\frac{1}{n} \\sum_{j=1}^{n} \n",
    "    \\bigl(x_{i,j} - \\hat{x}_{i,j}\\bigr)^2\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $N$ es el número total de muestras.\n",
    "- $d$ es la dimensión de cada muestra $\\mathbf{x}_i$.\n",
    "- $x_{i,j}$ y $\\hat{x}_{i,j}$ representan la $j$-ésima componente de la muestra $\\mathbf{x}_i$ y de su reconstrucción, respectivamente.\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary>Nota: Sobre algunas otras funciones de pérdida. </summary>\n",
    "\n",
    "El **Error cuadrático medio** es ideal para datos continuos, como imágenes con valores reales. Es fácil de usar y da resultados estables, pero puede generar salidas borrosas porque penaliza fuertemente los errores grandes.\n",
    "\n",
    "**Binary Crossentropy** se usa cuando los datos están entre 0 y 1, como imágenes normalizadas. Funciona bien con activaciones como sigmoide, y modela la probabilidad de cada píxel o bit.\n",
    "\n",
    "La Binary Crossentropy se expresa como:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{BCE} = \n",
    "- \\frac{1}{N \\times d} \\sum_{i=1}^{N} \\sum_{j=1}^{d}\n",
    "\\Bigl[\n",
    "    x_{i,j} \\, \\log\\bigl(\\hat{x}_{i,j}\\bigr) \n",
    "    +\n",
    "    \\bigl(1 - x_{i,j}\\bigr) \\, \\log\\bigl(1 - \\hat{x}_{i,j}\\bigr)\n",
    "\\Bigr],\n",
    "$$\n",
    "\n",
    "donde $ d $ es la dimensión de cada muestra, $ x_{i,j} \\in \\{0,1\\} $ y $ \\hat{x}_{i,j} $ es la probabilidad estimada por el modelo para dicha componente. Esta función de pérdida castiga fuertemente aquellas predicciones en las que $ \\hat{x}_{i,j} $ difiere de $ x_{i,j} $ con alto grado de confianza (debido al uso del logaritmo).\n",
    "\n",
    "\n",
    "**Categorical Crossentropy** es más adecuada cuando la salida son categorías, como texto o etiquetas. \n",
    "Para cuando cada muestra $ \\mathbf{x}_i $ pertenece a una de $ K $ categorías y se representa en formato *one-hot* (solo una de sus $ K $ posiciones es 1, mientras que el resto son 0), tenemos la **Categorical Crossentropy**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{CCE} =\n",
    "- \\frac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "\\sum_{k=1}^{K}\n",
    "x_{i,k} \\,\\log\\bigl(\\hat{x}_{i,k}\\bigr),\n",
    "$$\n",
    "\n",
    "donde $ x_{i,k} $ es 1 si la clase $ k $ es la correcta para la muestra $ \\mathbf{x}_i $, y $ \\hat{x}_{i,k} $ es la probabilidad que el modelo asigna a la clase $ k $. El objetivo en este caso es alinear la distribución pronosticada con la verdadera, penalizando fuertemente cuando la probabilidad de la clase correcta resulta ser baja.\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "### **Optimización**\n",
    "El objetivo es encontrar los parámetros $\\theta$ y $\\phi$ que minimicen la función de pérdida:\n",
    "\n",
    "$$\n",
    "\\theta^*, \\phi^* = \\arg \\min_{\\theta, \\phi} \\,\\mathcal{L}_{MSE}.\n",
    "$$\n",
    "\n",
    "La optimización se resuelve mediante **descenso de gradiente**, por ejemplo usando una tasa de aprendizaje $\\eta$:\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta - \\eta\\,\\nabla_{\\theta} \\,\\mathcal{L}_{MSE},\n",
    "\\quad\n",
    "\\phi \\leftarrow \\phi - \\eta\\,\\nabla_{\\phi} \\,\\mathcal{L}_{MSE}.\n",
    "$$\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Nota: Sobre la optimizacion</summary>\n",
    "\n",
    "Hay diferentes formas de optimizacion. \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sparse Autoencoder**\n",
    "\n",
    "Los sparse autoencoders respetan la estructura del \"autoencoder simple\" y simplemente se añade un término de penalización que fomenta activaciones promedio bajas en la capa latente, lo que provoca la dispersión:\n",
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Nota: Otro tipo de funcion de perdida </summary>\n",
    "\n",
    "**Activación promedio de la neurona $j$:**  \n",
    "   Sea $\\mathbf{z}_i = f_{\\theta}(\\mathbf{x}_i)$ la salida del encoder para la muestra $i$. La **activación promedio** de la neurona $j$ es:\n",
    "\n",
    "   $$\n",
    "   \\hat{\\rho}_j = \\frac{1}{N}\\sum_{i=1}^N z_{i,j}.\n",
    "   $$\n",
    "\n",
    "**Penalización (Divergencia KL):**  \n",
    "   Se define $\\rho$ como la activación deseada (por ejemplo, $\\rho=0.05$). La desviación de $\\hat{\\rho}_j$ respecto a $\\rho$ se mide con la **Divergencia KL**:\n",
    "\n",
    "   $$\n",
    "   \\mathrm{KL}\\bigl(\\rho \\,\\|\\, \\hat{\\rho}_j\\bigr)\n",
    "   =\n",
    "   \\rho \\,\\log \\frac{\\rho}{\\hat{\\rho}_j}\n",
    "   \\;+\\;\n",
    "   (1-\\rho)\\,\\log \\frac{1-\\rho}{\\,1-\\hat{\\rho}_j}.\n",
    "   $$\n",
    "\n",
    "**Función de costo total (con dispersión):**  \n",
    "   El término de esparsidad se agrega al MSE multiplicado por un factor $\\beta$:\n",
    "\n",
    "   $$\n",
    "   \\mathcal{L}_{Sparse}\n",
    "   =\n",
    "   \\mathcal{L}_{MSE}\n",
    "   \\;+\\;\n",
    "   \\beta \\sum_{j=1}^{m} \n",
    "   \\mathrm{KL}\\bigl(\\rho \\,\\|\\, \\hat{\\rho}_j\\bigr).\n",
    "   $$\n",
    "\n",
    "Este término adicional obliga a que la **activación promedio** de cada neurona $\\hat{\\rho}_j$ se acerque a $\\rho$, convirtiendo así un autoencoder normal en un **autoencoder *sparse***.\n",
    "\n",
    "\n",
    "### Definición General de la Divergencia KL\n",
    "\n",
    "La divergencia KL entre dos distribuciones de probabilidad $P(x)$ y $Q(x)$ se define como:\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\,\\|\\, Q) \\;=\\; \\sum_{x} P(x)\\,\\log\\!\\Bigl(\\tfrac{P(x)}{Q(x)}\\Bigr).\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $P(x)$ es la distribución de referencia.\n",
    "- $Q(x)$ es la distribución que usamos para aproximar a $P(x)$.\n",
    "- La divergencia KL mide cuánta información se pierde cuando usamos $Q(x)$ en lugar de $P(x)$.\n",
    "\n",
    "El principal objetivo de la divergencia de Kullback-Leibler (KL) es medir cuánta información se pierde cuando usamos una distribución de probabilidad 𝑄 para aproximar otra distribución P. En otras palabras, mide la diferencia entre dos distribuciones de probabilidad y nos dice cuánto nos alejamos de la distribución \"verdadera\" al usar una aproximación.\n",
    "\n",
    "\n",
    "-- Imagen del articulo pendiente:  Solomon Kullback y Richard A. Leibler en su artículo de 1951: \"On Information and Sufficiency\".\n",
    "\n",
    "\n",
    "### Divergencia KL con Bernoulli\n",
    "\n",
    "Cuando $P$ y $Q$ son distribuciones de Bernoulli con parámetros $\\rho$ y $\\hat{\\rho}_j$, respectivamente, la variable aleatoria $X$ solo puede tomar los valores $0$ o $1$. Entonces:\n",
    "\n",
    "- Para $X = 1$:\n",
    "  \n",
    "  $$\n",
    "  P(1) = \\rho, \\quad Q(1) = \\hat{\\rho}_j.\n",
    "  $$\n",
    "  \n",
    "- Para $X = 0$:\n",
    "  \n",
    "  $$\n",
    "  P(0) = 1 - \\rho, \\quad Q(0) = 1 - \\hat{\\rho}_j.\n",
    "  $$\n",
    "\n",
    "Aplicamos la definición de la divergencia KL:\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\,\\|\\, Q) \n",
    "= \\sum_{x \\in \\{0,1\\}} P(x) \\log \\frac{P(x)}{Q(x)}.\n",
    "$$\n",
    "\n",
    "entonces,\n",
    "\n",
    "$$\n",
    "D_{KL}(\\text{Bern}(\\rho) \\,\\|\\, \\text{Bern}(\\hat{\\rho}_j))\n",
    "=\n",
    "\\rho \\,\\log\\!\\Bigl(\\tfrac{\\rho}{\\hat{\\rho}_j}\\Bigr)\n",
    "\\;+\\;\n",
    "(1-\\rho)\\,\\log\\!\\Bigl(\\tfrac{1-\\rho}{1-\\hat{\\rho}_j}\\Bigr).\n",
    "$$\n",
    "\n",
    "Esto nos da la divergencia KL específica para dos distribuciones Bernoulli.\n",
    "\n",
    "\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
