{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Autoencoders: Formulaci贸n Matem谩tica**\n",
    "\n",
    "El estudio de los autoencoders, en general, es importante para poder interpretar lo que aprenden los modelos Transformer. Esta es una de las herramientas m谩s \n",
    "utilizadas actualmente para la interpretaci贸n de dichos modelos. En esta secci贸n se analizar谩 la estructura matem谩tica de los autoencoders simples y, posteriormente,\n",
    " de los autoencoders sparsos, los cuales incorporan peque帽as penalizaciones en la funci贸n de p茅rdida. Estas penalizaciones les otorgan propiedades particulares que \n",
    " pueden ser 煤tiles para nuestros fines.\n",
    "\n",
    "\n",
    "## **Autoencoder Simple**\n",
    "\n",
    "\n",
    "### **Definici贸n del Autoencoder**\n",
    "Un **autoencoder** es una funci贸n compuesta $ h: \\mathcal{X} \\to \\mathcal{X} $ definida por la composici贸n de dos funciones diferenciables:\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}) = g_{\\phi}\\bigl(f_{\\theta}(\\mathbf{x})\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $f_{\\theta}: \\mathcal{X} \\to \\mathbb{R}^m$ es la **funci贸n de codificaci贸n (encoder)**.\n",
    "- $g_{\\phi}: \\mathbb{R}^m \\to \\mathcal{X}$ es la **funci贸n de decodificaci贸n (decoder)**.\n",
    "\n",
    "El objetivo del autoencoder es encontrar los par谩metros $\\theta$ y $\\phi$ tales que $h(\\mathbf{x}) \\approx \\mathbf{x}$, minimizando una funci贸n de p茅rdida adecuada.\n",
    "\n",
    "\n",
    "### **Codificador (Encoder)**\n",
    "El encoder transforma la entrada $\\mathbf{x} \\in \\mathbb{R}^n$ en una representaci贸n latente $\\mathbf{z} \\in \\mathbb{R}^m$, con $m < n$ en el caso de reducci贸n de dimensionalidad:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = f_{\\theta}(\\mathbf{x}) = \\sigma\\bigl(W_e \\,\\mathbf{x} + \\mathbf{b}_e\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $W_e \\in \\mathbb{R}^{m \\times n}$ es la **matriz de pesos del encoder**.\n",
    "- $\\mathbf{b}_e \\in \\mathbb{R}^{m}$ es el **vector de sesgo**.\n",
    "- $\\sigma: \\mathbb{R} \\to \\mathbb{R}$ es una funci贸n de activaci贸n (**ReLU**, **Sigmoid**, **Tanh**).\n",
    "- $\\mathbf{z} \\in \\mathbb{R}^{m}$ es la representaci贸n latente.\n",
    "\n",
    "\n",
    "### **Decodificador (Decoder)**\n",
    "El decoder reconstruye la entrada original a partir de $\\mathbf{z}$:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}} = g_{\\phi}(\\mathbf{z}) = \\sigma'\\bigl(W_d \\,\\mathbf{z} + \\mathbf{b}_d\\bigr)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $W_d \\in \\mathbb{R}^{n \\times m}$ es la **matriz de pesos del decoder**.\n",
    "- $\\mathbf{b}_d \\in \\mathbb{R}^{n}$ es el **vector de sesgo**.\n",
    "- $\\sigma': \\mathbb{R} \\to \\mathbb{R}$ es una funci贸n de activaci贸n (puede diferir de $\\sigma$).\n",
    "- $\\hat{\\mathbf{x}} \\in \\mathbb{R}^n$ es la **reconstrucci贸n de la entrada**.\n",
    "\n",
    "\n",
    "### **Funci贸n de P茅rdida**\n",
    "\n",
    "Es importante considerar que la funci贸n de p茅rdida puede variar. En principio, el error cuadr谩tico medio (Mean Squared Error, MSE) es una de las m谩s utilizadas en autoencoders simples; sin embargo, dependiendo de la tarea a realizar, en algunos casos conviene m谩s utilizar una u otra.\n",
    "\n",
    "Para un conjunto de datos \n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{\\mathbf{x}_i\\}_{i=1}^{N},\n",
    "$$\n",
    "\n",
    "el entrenamiento del autoencoder minimiza la diferencia entre la entrada $\\mathbf{x}_i$ y la reconstrucci贸n $\\hat{\\mathbf{x}}_i$. Usamos el **Error Cuadr谩tico Medio (MSE)** promediado:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{MSE} = \\frac{1}{N} \\sum_{i=1}^{N}\n",
    "\\left(\n",
    "    \\frac{1}{n} \\sum_{j=1}^{n} \n",
    "    \\bigl(x_{i,j} - \\hat{x}_{i,j}\\bigr)^2\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $N$ es el n煤mero total de muestras.\n",
    "- $d$ es la dimensi贸n de cada muestra $\\mathbf{x}_i$.\n",
    "- $x_{i,j}$ y $\\hat{x}_{i,j}$ representan la $j$-茅sima componente de la muestra $\\mathbf{x}_i$ y de su reconstrucci贸n, respectivamente.\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary>Nota: Sobre algunas otras funciones de p茅rdida. </summary>\n",
    "\n",
    "El **Error cuadr谩tico medio** es ideal para datos continuos, como im谩genes con valores reales. Es f谩cil de usar y da resultados estables, pero puede generar salidas borrosas porque penaliza fuertemente los errores grandes.\n",
    "\n",
    "**Binary Crossentropy** se usa cuando los datos est谩n entre 0 y 1, como im谩genes normalizadas. Funciona bien con activaciones como sigmoide, y modela la probabilidad de cada p铆xel o bit.\n",
    "\n",
    "La Binary Crossentropy se expresa como:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{BCE} = \n",
    "- \\frac{1}{N \\times d} \\sum_{i=1}^{N} \\sum_{j=1}^{d}\n",
    "\\Bigl[\n",
    "    x_{i,j} \\, \\log\\bigl(\\hat{x}_{i,j}\\bigr) \n",
    "    +\n",
    "    \\bigl(1 - x_{i,j}\\bigr) \\, \\log\\bigl(1 - \\hat{x}_{i,j}\\bigr)\n",
    "\\Bigr],\n",
    "$$\n",
    "\n",
    "donde $ d $ es la dimensi贸n de cada muestra, $ x_{i,j} \\in \\{0,1\\} $ y $ \\hat{x}_{i,j} $ es la probabilidad estimada por el modelo para dicha componente. Esta funci贸n de p茅rdida castiga fuertemente aquellas predicciones en las que $ \\hat{x}_{i,j} $ difiere de $ x_{i,j} $ con alto grado de confianza (debido al uso del logaritmo).\n",
    "\n",
    "\n",
    "**Categorical Crossentropy** es m谩s adecuada cuando la salida son categor铆as, como texto o etiquetas. \n",
    "Para cuando cada muestra $ \\mathbf{x}_i $ pertenece a una de $ K $ categor铆as y se representa en formato *one-hot* (solo una de sus $ K $ posiciones es 1, mientras que el resto son 0), tenemos la **Categorical Crossentropy**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{CCE} =\n",
    "- \\frac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "\\sum_{k=1}^{K}\n",
    "x_{i,k} \\,\\log\\bigl(\\hat{x}_{i,k}\\bigr),\n",
    "$$\n",
    "\n",
    "donde $ x_{i,k} $ es 1 si la clase $ k $ es la correcta para la muestra $ \\mathbf{x}_i $, y $ \\hat{x}_{i,k} $ es la probabilidad que el modelo asigna a la clase $ k $. El objetivo en este caso es alinear la distribuci贸n pronosticada con la verdadera, penalizando fuertemente cuando la probabilidad de la clase correcta resulta ser baja.\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "### **Optimizaci贸n**\n",
    "El objetivo es encontrar los par谩metros $\\theta$ y $\\phi$ que minimicen la funci贸n de p茅rdida:\n",
    "\n",
    "$$\n",
    "\\theta^*, \\phi^* = \\arg \\min_{\\theta, \\phi} \\,\\mathcal{L}_{MSE}.\n",
    "$$\n",
    "\n",
    "La optimizaci贸n se resuelve mediante **descenso de gradiente**, por ejemplo usando una tasa de aprendizaje $\\eta$:\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta - \\eta\\,\\nabla_{\\theta} \\,\\mathcal{L}_{MSE},\n",
    "\\quad\n",
    "\\phi \\leftarrow \\phi - \\eta\\,\\nabla_{\\phi} \\,\\mathcal{L}_{MSE}.\n",
    "$$\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Nota: Sobre la optimizacion</summary>\n",
    "\n",
    "Hay diferentes formas de optimizacion. \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sparse Autoencoder**\n",
    "\n",
    "Los sparse autoencoders respetan la estructura del \"autoencoder simple\" y simplemente se a帽ade un t茅rmino de penalizaci贸n que fomenta activaciones promedio bajas en la capa latente, lo que provoca la dispersi贸n:\n",
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Nota: Otro tipo de funcion de perdida </summary>\n",
    "\n",
    "**Activaci贸n promedio de la neurona $j$:**  \n",
    "   Sea $\\mathbf{z}_i = f_{\\theta}(\\mathbf{x}_i)$ la salida del encoder para la muestra $i$. La **activaci贸n promedio** de la neurona $j$ es:\n",
    "\n",
    "   $$\n",
    "   \\hat{\\rho}_j = \\frac{1}{N}\\sum_{i=1}^N z_{i,j}.\n",
    "   $$\n",
    "\n",
    "**Penalizaci贸n (Divergencia KL):**  \n",
    "   Se define $\\rho$ como la activaci贸n deseada (por ejemplo, $\\rho=0.05$). La desviaci贸n de $\\hat{\\rho}_j$ respecto a $\\rho$ se mide con la **Divergencia KL**:\n",
    "\n",
    "   $$\n",
    "   \\mathrm{KL}\\bigl(\\rho \\,\\|\\, \\hat{\\rho}_j\\bigr)\n",
    "   =\n",
    "   \\rho \\,\\log \\frac{\\rho}{\\hat{\\rho}_j}\n",
    "   \\;+\\;\n",
    "   (1-\\rho)\\,\\log \\frac{1-\\rho}{\\,1-\\hat{\\rho}_j}.\n",
    "   $$\n",
    "\n",
    "**Funci贸n de costo total (con dispersi贸n):**  \n",
    "   El t茅rmino de esparsidad se agrega al MSE multiplicado por un factor $\\beta$:\n",
    "\n",
    "   $$\n",
    "   \\mathcal{L}_{Sparse}\n",
    "   =\n",
    "   \\mathcal{L}_{MSE}\n",
    "   \\;+\\;\n",
    "   \\beta \\sum_{j=1}^{m} \n",
    "   \\mathrm{KL}\\bigl(\\rho \\,\\|\\, \\hat{\\rho}_j\\bigr).\n",
    "   $$\n",
    "\n",
    "Este t茅rmino adicional obliga a que la **activaci贸n promedio** de cada neurona $\\hat{\\rho}_j$ se acerque a $\\rho$, convirtiendo as铆 un autoencoder normal en un **autoencoder *sparse***.\n",
    "\n",
    "\n",
    "### Definici贸n General de la Divergencia KL\n",
    "\n",
    "La divergencia KL entre dos distribuciones de probabilidad $P(x)$ y $Q(x)$ se define como:\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\,\\|\\, Q) \\;=\\; \\sum_{x} P(x)\\,\\log\\!\\Bigl(\\tfrac{P(x)}{Q(x)}\\Bigr).\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $P(x)$ es la distribuci贸n de referencia.\n",
    "- $Q(x)$ es la distribuci贸n que usamos para aproximar a $P(x)$.\n",
    "- La divergencia KL mide cu谩nta informaci贸n se pierde cuando usamos $Q(x)$ en lugar de $P(x)$.\n",
    "\n",
    "El principal objetivo de la divergencia de Kullback-Leibler (KL) es medir cu谩nta informaci贸n se pierde cuando usamos una distribuci贸n de probabilidad  para aproximar otra distribuci贸n P. En otras palabras, mide la diferencia entre dos distribuciones de probabilidad y nos dice cu谩nto nos alejamos de la distribuci贸n \"verdadera\" al usar una aproximaci贸n.\n",
    "\n",
    "\n",
    "-- Imagen del articulo pendiente:  Solomon Kullback y Richard A. Leibler en su art铆culo de 1951: \"On Information and Sufficiency\".\n",
    "\n",
    "\n",
    "### Divergencia KL con Bernoulli\n",
    "\n",
    "Cuando $P$ y $Q$ son distribuciones de Bernoulli con par谩metros $\\rho$ y $\\hat{\\rho}_j$, respectivamente, la variable aleatoria $X$ solo puede tomar los valores $0$ o $1$. Entonces:\n",
    "\n",
    "- Para $X = 1$:\n",
    "  \n",
    "  $$\n",
    "  P(1) = \\rho, \\quad Q(1) = \\hat{\\rho}_j.\n",
    "  $$\n",
    "  \n",
    "- Para $X = 0$:\n",
    "  \n",
    "  $$\n",
    "  P(0) = 1 - \\rho, \\quad Q(0) = 1 - \\hat{\\rho}_j.\n",
    "  $$\n",
    "\n",
    "Aplicamos la definici贸n de la divergencia KL:\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\,\\|\\, Q) \n",
    "= \\sum_{x \\in \\{0,1\\}} P(x) \\log \\frac{P(x)}{Q(x)}.\n",
    "$$\n",
    "\n",
    "entonces,\n",
    "\n",
    "$$\n",
    "D_{KL}(\\text{Bern}(\\rho) \\,\\|\\, \\text{Bern}(\\hat{\\rho}_j))\n",
    "=\n",
    "\\rho \\,\\log\\!\\Bigl(\\tfrac{\\rho}{\\hat{\\rho}_j}\\Bigr)\n",
    "\\;+\\;\n",
    "(1-\\rho)\\,\\log\\!\\Bigl(\\tfrac{1-\\rho}{1-\\hat{\\rho}_j}\\Bigr).\n",
    "$$\n",
    "\n",
    "Esto nos da la divergencia KL espec铆fica para dos distribuciones Bernoulli.\n",
    "\n",
    "\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
