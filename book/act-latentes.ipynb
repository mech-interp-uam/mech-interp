{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretación de latentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=API_KEY) if API_KEY else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_activating_examples_gpt(api_key, n=10) -> list[tuple[int, list[str]]]:\n",
    "    \"\"\"\n",
    "    Simula ejemplos de activación máxima en frases relacionadas con comunicación.\n",
    "    Regresa el mismo formato que fetch_max_activating_examples().\n",
    "    \"\"\"\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    system_prompt = (\n",
    "    \"You are a fluent, context-aware asssistan that wirtes natural, varied, and meaningful sentences\"\n",
    "    \"related to the concept of commnication. Yout output will be used  to study neuron activations in a language model\"\n",
    "    \"Each sentence must contain exactly one significant token related to communication, and that token must be wrapped with double angle brackets like this: <<talk>>\"\n",
    "    \"Avoid generic language or filler. Ensure the token is conceptually central to the sentence's meaning\"\n",
    "    )\n",
    "    user_prompt = (\n",
    "        f\"Generate {n} short sentences (10 to 15 words each) about communication. \"\n",
    "        \"In each sentence, mark exactly one key word related to communication ussing double angle like this: <<talk>>\" \n",
    "        \"Return only the sentences, one per line, with no bullet poinsts, numbering, or explanations\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    raw_sentences = response.choices[0].message.content.strip().split(\"\\n\")\n",
    "    raw_sentences = [s.strip().lstrip(\"0123456789. \") for s in raw_sentences if s.strip()]\n",
    "\n",
    "    parsed = []\n",
    "    for i, sentence in enumerate(raw_sentences):\n",
    "        tokens = sentence.split()\n",
    "        for j, tok in enumerate(tokens):\n",
    "            if tok.startswith(\"<<\") and tok.endswith(\">>\"):\n",
    "                tokens[j] = f\"<<{tok.strip('<>')}>>\"\n",
    "                break\n",
    "        parsed.append((i, tokens))\n",
    "\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_gpt4o_from_simulated(examples: list[tuple[int, list[str]]], use_chain_of_thought=True) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Construye un prompt de GPT-4o a partir de ejemplos simulados con tokens activadores marcados.\n",
    "    \"\"\"\n",
    "    formatted = \"\\n\".join(f\"{i+1}. {' '.join(tokens)}\" for i, tokens in examples)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are analyzing a latent neuron in a transformer-based language model. \"\n",
    "        \"Each sentence below contains one token that strongly activates this latent neuron, highlighted using << >>. \"\n",
    "        \"Your task is to interpret what concept, theme, or category this neuron responds to. \"\n",
    "        \"Be precise but not overly narrow. Use fewer than 20 words. \"\n",
    "        \"Avoid punctuation, lists, formatting, or generic labels like 'words' or 'nouns'. \"\n",
    "        \"Focus on shared semantic meaning across the highlighted tokens.\"\n",
    "    )\n",
    "\n",
    "    assistant_prompt = (\n",
    "        \"Start by mentally grouping the highlighted tokens into a conceptual category. \"\n",
    "        \"Then, write a final interpretation in fewer than 20 words. \"\n",
    "        \"This neuron activates on\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"system\": system_prompt,\n",
    "        \"user\": f\"The activating examples are:\\n\\n{formatted}\",\n",
    "        \"assistant\": assistant_prompt,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt4o_explanation_from_prompt(prompts: dict, n_completions=3, max_tokens=100) -> list[str]:\n",
    "    \"\"\"\n",
    "    Llama a la API de GPT-4o con un prompt ya generado y devuelve las interpretaciones.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompts[\"system\"]},\n",
    "            {\"role\": \"user\", \"content\": prompts[\"user\"]},\n",
    "            {\"role\": \"assistant\", \"content\": prompts[\"assistant\"]},\n",
    "        ],\n",
    "        n=n_completions,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return [choice.message.content.strip() for choice in response.choices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if API_KEY:\n",
    "    simulated_examples = simulate_activating_examples_gpt(api_key=API_KEY, n=10)\n",
    "    prompt = create_prompt_gpt4o_from_simulated(simulated_examples, use_chain_of_thought=True)\n",
    "    explanations = get_gpt4o_explanation_from_prompt(prompt, n_completions=3)\n",
    "\n",
    "    for i, exp in enumerate(explanations):\n",
    "        print(f\"[Explicación {i+1}]: {exp}\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY no está configurada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
